{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "098ca605",
   "metadata": {},
   "source": [
    "# Importing the data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "6197d918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.No</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>culture</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>mother</th>\n",
       "      <th>father</th>\n",
       "      <th>heir</th>\n",
       "      <th>house</th>\n",
       "      <th>spouse</th>\n",
       "      <th>...</th>\n",
       "      <th>isAliveMother</th>\n",
       "      <th>isAliveFather</th>\n",
       "      <th>isAliveHeir</th>\n",
       "      <th>isAliveSpouse</th>\n",
       "      <th>isMarried</th>\n",
       "      <th>isNoble</th>\n",
       "      <th>age</th>\n",
       "      <th>numDeadRelations</th>\n",
       "      <th>popularity</th>\n",
       "      <th>isAlive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Viserys II Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rhaenyra Targaryen</td>\n",
       "      <td>Daemon Targaryen</td>\n",
       "      <td>Aegon IV Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0.605351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Walder Frey</td>\n",
       "      <td>Lord of the Crossing</td>\n",
       "      <td>Rivermen</td>\n",
       "      <td>208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Frey</td>\n",
       "      <td>Perra Royce</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Addison Hill</td>\n",
       "      <td>Ser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Swyft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Aemma Arryn</td>\n",
       "      <td>Queen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Arryn</td>\n",
       "      <td>Viserys I Targaryen</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sylva Santagar</td>\n",
       "      <td>Greenstone</td>\n",
       "      <td>Dornish</td>\n",
       "      <td>276.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Santagar</td>\n",
       "      <td>Eldon Estermont</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Tommen Baratheon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cersei Lannister</td>\n",
       "      <td>Robert Baratheon</td>\n",
       "      <td>Myrcella Baratheon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Valarr Targaryen</td>\n",
       "      <td>Hand of the King</td>\n",
       "      <td>Valyrian</td>\n",
       "      <td>183.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Targaryen</td>\n",
       "      <td>Kiera of Tyrosh</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Viserys I Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alyssa Targaryen</td>\n",
       "      <td>Baelon Targaryen</td>\n",
       "      <td>Rhaenyra Targaryen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.678930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Wilbert</td>\n",
       "      <td>Ser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Wilbert Osgrey</td>\n",
       "      <td>Ser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>House Osgrey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.No                  name                 title   culture  dateOfBirth  \\\n",
       "0     1  Viserys II Targaryen                   NaN       NaN          NaN   \n",
       "1     2           Walder Frey  Lord of the Crossing  Rivermen        208.0   \n",
       "2     3          Addison Hill                   Ser       NaN          NaN   \n",
       "3     4           Aemma Arryn                 Queen       NaN         82.0   \n",
       "4     5        Sylva Santagar            Greenstone   Dornish        276.0   \n",
       "5     6      Tommen Baratheon                   NaN       NaN          NaN   \n",
       "6     7      Valarr Targaryen      Hand of the King  Valyrian        183.0   \n",
       "7     8   Viserys I Targaryen                   NaN       NaN          NaN   \n",
       "8     9               Wilbert                   Ser       NaN          NaN   \n",
       "9    10        Wilbert Osgrey                   Ser       NaN          NaN   \n",
       "\n",
       "               mother            father                heir            house  \\\n",
       "0  Rhaenyra Targaryen  Daemon Targaryen  Aegon IV Targaryen              NaN   \n",
       "1                 NaN               NaN                 NaN       House Frey   \n",
       "2                 NaN               NaN                 NaN      House Swyft   \n",
       "3                 NaN               NaN                 NaN      House Arryn   \n",
       "4                 NaN               NaN                 NaN   House Santagar   \n",
       "5    Cersei Lannister  Robert Baratheon  Myrcella Baratheon              NaN   \n",
       "6                 NaN               NaN                 NaN  House Targaryen   \n",
       "7    Alyssa Targaryen  Baelon Targaryen  Rhaenyra Targaryen              NaN   \n",
       "8                 NaN               NaN                 NaN              NaN   \n",
       "9                 NaN               NaN                 NaN     House Osgrey   \n",
       "\n",
       "                spouse  ...  isAliveMother  isAliveFather  isAliveHeir  \\\n",
       "0                  NaN  ...            1.0            0.0          0.0   \n",
       "1          Perra Royce  ...            NaN            NaN          NaN   \n",
       "2                  NaN  ...            NaN            NaN          NaN   \n",
       "3  Viserys I Targaryen  ...            NaN            NaN          NaN   \n",
       "4      Eldon Estermont  ...            NaN            NaN          NaN   \n",
       "5                  NaN  ...            1.0            1.0          1.0   \n",
       "6      Kiera of Tyrosh  ...            NaN            NaN          NaN   \n",
       "7                  NaN  ...            1.0            1.0          1.0   \n",
       "8                  NaN  ...            NaN            NaN          NaN   \n",
       "9                  NaN  ...            NaN            NaN          NaN   \n",
       "\n",
       "   isAliveSpouse  isMarried  isNoble   age  numDeadRelations  popularity  \\\n",
       "0            NaN          0        0   NaN                11    0.605351   \n",
       "1            1.0          1        1  97.0                 1    0.896321   \n",
       "2            NaN          0        1   NaN                 0    0.267559   \n",
       "3            0.0          1        1  23.0                 0    0.183946   \n",
       "4            1.0          1        1  29.0                 0    0.043478   \n",
       "5            NaN          0        0   NaN                 5    1.000000   \n",
       "6            1.0          1        1  26.0                 0    0.431438   \n",
       "7            NaN          0        0   NaN                 5    0.678930   \n",
       "8            NaN          0        1   NaN                 0    0.006689   \n",
       "9            NaN          0        1   NaN                 0    0.020067   \n",
       "\n",
       "   isAlive  \n",
       "0        0  \n",
       "1        1  \n",
       "2        1  \n",
       "3        0  \n",
       "4        1  \n",
       "5        1  \n",
       "6        0  \n",
       "7        0  \n",
       "8        0  \n",
       "9        1  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries\n",
    "import pandas            as pd                          # data science essentials\n",
    "import matplotlib.pyplot as plt                         # data visualization\n",
    "import seaborn           as sns                         # enhanced data viz\n",
    "from sklearn.model_selection import train_test_split    # train-test split\n",
    "from sklearn.linear_model import LogisticRegression     # logistic regression\n",
    "import statsmodels.formula.api as smf                   # logistic regression\n",
    "from sklearn.metrics import confusion_matrix            # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score               # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier      # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor       # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler        # standard scaler\n",
    "from sklearn.tree import DecisionTreeClassifier         # classification trees\n",
    "from sklearn.tree import plot_tree                      # tree plots\n",
    "import numpy as np                                      # mathematical essentials\n",
    "from sklearn.model_selection import RandomizedSearchCV  # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer                 # customizable scorer\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "\n",
    "\n",
    "# loading data\n",
    "file = './GOT_character_predictions.xlsx'\n",
    "\n",
    "got_df = pd.read_excel(io         = file,\n",
    "                      header     = 0,\n",
    "                      sheet_name = 0)\n",
    "\n",
    "\n",
    "\n",
    "# displaying the head of the dataset\n",
    "got_df.head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4791fb5",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f597d",
   "metadata": {},
   "source": [
    "After looking at the features names, I noticed one of them would be an issue in the future regression because of the dot in the name. I renamed it with an underscore to avoid potential error related to the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "d3774b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming S.No feature \n",
    "got_df.rename(columns={'S.No':'S_No'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "2980b527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1946 entries, 0 to 1945\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   S_No                        1946 non-null   int64  \n",
      " 1   name                        1946 non-null   object \n",
      " 2   title                       938 non-null    object \n",
      " 3   culture                     677 non-null    object \n",
      " 4   dateOfBirth                 433 non-null    float64\n",
      " 5   mother                      21 non-null     object \n",
      " 6   father                      26 non-null     object \n",
      " 7   heir                        23 non-null     object \n",
      " 8   house                       1519 non-null   object \n",
      " 9   spouse                      276 non-null    object \n",
      " 10  book1_A_Game_Of_Thrones     1946 non-null   int64  \n",
      " 11  book2_A_Clash_Of_Kings      1946 non-null   int64  \n",
      " 12  book3_A_Storm_Of_Swords     1946 non-null   int64  \n",
      " 13  book4_A_Feast_For_Crows     1946 non-null   int64  \n",
      " 14  book5_A_Dance_with_Dragons  1946 non-null   int64  \n",
      " 15  isAliveMother               21 non-null     float64\n",
      " 16  isAliveFather               26 non-null     float64\n",
      " 17  isAliveHeir                 23 non-null     float64\n",
      " 18  isAliveSpouse               276 non-null    float64\n",
      " 19  isMarried                   1946 non-null   int64  \n",
      " 20  isNoble                     1946 non-null   int64  \n",
      " 21  age                         433 non-null    float64\n",
      " 22  numDeadRelations            1946 non-null   int64  \n",
      " 23  popularity                  1946 non-null   float64\n",
      " 24  isAlive                     1946 non-null   int64  \n",
      "dtypes: float64(7), int64(10), object(8)\n",
      "memory usage: 380.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# getting dataset information\n",
    "got_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98738730",
   "metadata": {},
   "source": [
    "I loaded the user-defined functions in case I would need them in the following steps of the assignment. The code is taken from script 7 of Machine Learning (Chase Kusterer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "b8784e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# optimal_neighbors\n",
    "########################################\n",
    "def optimal_neighbors(x_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.10,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "x_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the x data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing x_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(x_data)\n",
    "        x_scaled           = scaler.transform(x_data)\n",
    "        x_scaled_df        = pd.DataFrame(x_scaled)\n",
    "        x_data             = x_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n",
    "\n",
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "Creates a visualization of a confusion matrix.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "true_y : true values for the response variable\n",
    "pred_y : predicted values for the response variable\n",
    "labels : , default None\n",
    "    \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "4b68e9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       433.000000\n",
       "mean      -1293.563510\n",
       "std       19564.340993\n",
       "min     -298001.000000\n",
       "25%          18.000000\n",
       "50%          27.000000\n",
       "75%          50.000000\n",
       "max         100.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptive statistics of age\n",
    "got_df['age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a229846",
   "metadata": {},
   "source": [
    "After displaying the descriptive statistics of age, I noticed the minimum value did not make sense. Hence, I highlighted the uncommon values in the following code, but did not modify them due to the restrictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "ebd14799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329          0.0\n",
       "790          0.0\n",
       "1684   -277980.0\n",
       "1868   -298001.0\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying all observations equal or lower than zero for age\n",
    "got_df.loc[:,'age'][got_df.loc[:,'age']<=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "c2848d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1946.000000\n",
       "mean        0.089584\n",
       "std         0.160568\n",
       "min         0.000000\n",
       "25%         0.013378\n",
       "50%         0.033445\n",
       "75%         0.086957\n",
       "max         1.000000\n",
       "Name: popularity, dtype: float64"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptive statistics of popularity\n",
    "got_df['popularity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "ad4ca0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       433.000000\n",
       "mean       1577.364896\n",
       "std       19565.414460\n",
       "min         -28.000000\n",
       "25%         240.000000\n",
       "50%         268.000000\n",
       "75%         285.000000\n",
       "max      298299.000000\n",
       "Name: dateOfBirth, dtype: float64"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptive statistics of dateOfBirth\n",
    "got_df['dateOfBirth'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a102e72",
   "metadata": {},
   "source": [
    "## Missing Values Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "a4608e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S_No                             0\n",
       "name                             0\n",
       "title                         1008\n",
       "culture                       1269\n",
       "dateOfBirth                   1513\n",
       "mother                        1925\n",
       "father                        1920\n",
       "heir                          1923\n",
       "house                          427\n",
       "spouse                        1670\n",
       "book1_A_Game_Of_Thrones          0\n",
       "book2_A_Clash_Of_Kings           0\n",
       "book3_A_Storm_Of_Swords          0\n",
       "book4_A_Feast_For_Crows          0\n",
       "book5_A_Dance_with_Dragons       0\n",
       "isAliveMother                 1925\n",
       "isAliveFather                 1920\n",
       "isAliveHeir                   1923\n",
       "isAliveSpouse                 1670\n",
       "isMarried                        0\n",
       "isNoble                          0\n",
       "age                           1513\n",
       "numDeadRelations                 0\n",
       "popularity                       0\n",
       "isAlive                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the number of missing value\n",
    "got_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "e4990af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S_No', 'name', 'title', 'culture', 'dateOfBirth', 'mother', 'father',\n",
       "       'heir', 'house', 'spouse', 'book1_A_Game_Of_Thrones',\n",
       "       'book2_A_Clash_Of_Kings', 'book3_A_Storm_Of_Swords',\n",
       "       'book4_A_Feast_For_Crows', 'book5_A_Dance_with_Dragons',\n",
       "       'isAliveMother', 'isAliveFather', 'isAliveHeir', 'isAliveSpouse',\n",
       "       'isMarried', 'isNoble', 'age', 'numDeadRelations', 'popularity',\n",
       "       'isAlive'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying all dataset columns\n",
    "got_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "09085c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m_title            1008\n",
       "m_culture          1269\n",
       "m_dateOfBirth      1513\n",
       "m_mother           1925\n",
       "m_father           1920\n",
       "m_heir             1923\n",
       "m_house             427\n",
       "m_spouse           1670\n",
       "m_isAliveMother    1925\n",
       "m_isAliveFather    1920\n",
       "m_isAliveHeir      1923\n",
       "m_isAliveSpouse    1670\n",
       "m_age              1513\n",
       "dtype: int64"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looping to detect features with missing values\n",
    "for col in got_df:\n",
    "\n",
    "    # creating columns with 1s if missing and 0 if not\n",
    "    if got_df[col].isnull().astype(int).sum() > 0:\n",
    "        got_df['m_'+col] = got_df[col].isnull().astype(int)\n",
    "\n",
    "\n",
    "# summing the missing value flags to check the results of the loop above\n",
    "got_df[    ['m_title', 'm_culture', 'm_dateOfBirth', 'm_mother', 'm_father',\n",
    "            'm_heir', 'm_house', 'm_spouse', 'm_isAliveMother', 'm_isAliveFather',\n",
    "            'm_isAliveHeir', 'm_isAliveSpouse', 'm_age']    ].sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baaa14c",
   "metadata": {},
   "source": [
    "## Flag Based Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803eb0e8",
   "metadata": {},
   "source": [
    "One of the variable (other than dummy) seemed to have a lot of zeros in the observations. I flagged this value since it had more than 100 observations in both counts (number of zeros and non-zeros observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "d887dace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                        No\t\tYes\n",
      "                        ---------------------\n",
      "numDeadRelations       | 1801\t\t145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# counting the number of zeroes for \n",
    "numDeadRelations_zeroes   = len(got_df['numDeadRelations'][got_df['numDeadRelations']==0]) \n",
    "\n",
    "# printing a table of the results\n",
    "print(f\"\"\"\n",
    "                        No\\t\\tYes\n",
    "                        ---------------------\n",
    "numDeadRelations       | {numDeadRelations_zeroes}\\t\\t{len(got_df) - numDeadRelations_zeroes}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "b25a7bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder variables\n",
    "got_df['has_dead_relations'] = 0\n",
    "\n",
    "for index, value in got_df.iterrows():\n",
    "    \n",
    "\n",
    "    # numDeadRelations\n",
    "    if got_df.loc[index, 'numDeadRelations'] > 0:\n",
    "        got_df.loc[index, 'has_dead_relations'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "a312b122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_dead_relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_dead_relations\n",
       "0                   1\n",
       "1                   1\n",
       "2                   0\n",
       "3                   0\n",
       "4                   0"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking results\n",
    "got_df[  ['has_dead_relations']  ].head(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b6a9c9",
   "metadata": {},
   "source": [
    "# Logistic Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b5838",
   "metadata": {},
   "source": [
    "## Stratifying the Response Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c884818",
   "metadata": {},
   "source": [
    "The following code shows the balance between the characters that are alive, and those who are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "fe9d6bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.75\n",
       "0    0.25\n",
       "Name: isAlive, dtype: float64"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got_df.loc[ : ,'isAlive'].value_counts(normalize = True).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90387b0e",
   "metadata": {},
   "source": [
    "## Preparing the Explanatory and Response Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "e40ca6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "got_data=got_df.drop('isAlive', axis=1)\n",
    "\n",
    "# declaring response variable\n",
    "got_target=got_df.loc[: , 'isAlive']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2d177f",
   "metadata": {},
   "source": [
    "## Prepare train-test split for statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "266a6ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_data,\n",
    "            got_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = got_target) # preserving balance\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "got_train = pd.concat([x_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "4cbbf23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Response Variable Proportions (Training Set)\n",
      "--------------------------------------------\n",
      "1    0.75\n",
      "0    0.25\n",
      "Name: isAlive, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "Response Variable Proportions (Testing Set)\n",
      "--------------------------------------------\n",
      "1    0.74\n",
      "0    0.26\n",
      "Name: isAlive, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing candidate variable sets\n",
    "print(f\"\"\"\n",
    "\n",
    "Response Variable Proportions (Training Set)\n",
    "--------------------------------------------\n",
    "{y_train.value_counts(normalize = True).round(decimals = 2)}\n",
    "\n",
    "\n",
    "\n",
    "Response Variable Proportions (Testing Set)\n",
    "--------------------------------------------\n",
    "{y_test.value_counts(normalize = True).round(decimals = 2)}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f064158",
   "metadata": {},
   "source": [
    "The following code is used to ease the selection and the imputation of variables in the logistic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "4d220532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " S_No + \n",
      " name + \n",
      " title + \n",
      " culture + \n",
      " dateOfBirth + \n",
      " mother + \n",
      " father + \n",
      " heir + \n",
      " house + \n",
      " spouse + \n",
      " book1_A_Game_Of_Thrones + \n",
      " book2_A_Clash_Of_Kings + \n",
      " book3_A_Storm_Of_Swords + \n",
      " book4_A_Feast_For_Crows + \n",
      " book5_A_Dance_with_Dragons + \n",
      " isAliveMother + \n",
      " isAliveFather + \n",
      " isAliveHeir + \n",
      " isAliveSpouse + \n",
      " isMarried + \n",
      " isNoble + \n",
      " age + \n",
      " numDeadRelations + \n",
      " popularity + \n",
      " m_title + \n",
      " m_culture + \n",
      " m_dateOfBirth + \n",
      " m_mother + \n",
      " m_father + \n",
      " m_heir + \n",
      " m_house + \n",
      " m_spouse + \n",
      " m_isAliveMother + \n",
      " m_isAliveFather + \n",
      " m_isAliveHeir + \n",
      " m_isAliveSpouse + \n",
      " m_age + \n",
      " has_dead_relations + \n"
     ]
    }
   ],
   "source": [
    "# creating a loop to avoid copy/paste errors\n",
    "for val in got_data:\n",
    "    print(f\" {val} + \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370057b5",
   "metadata": {},
   "source": [
    "## Logistic Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496d360f",
   "metadata": {},
   "source": [
    "The logistic_sig_1 (in the following cell) contains variables that have been selected based on this set of criteria:\n",
    "1. I removed all the variables that did not contain numbers.\n",
    "2. I removed all those with NaN values.\n",
    "3. At least one of the book variables was removed right away, to avoid a multi-collinearity scenario.\n",
    "4. All the variable that were related were removed (e.g.: isAliveFather -> m_father).\n",
    "5. From then , I removed one by one the variable with the highest p-value and observed the change.\n",
    "6. Finally, I removed m_age, although it had a p-value of 0. Indeed, I reckoned it was impossible to interpret such variable in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "0c6cf5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.490704\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.134</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1734.4441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 17:22</td>       <td>BIC:</td>         <td>1778.1876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-859.22</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>7</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1743</td>         <td>LLR p-value:</td>    <td>7.9817e-54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>              <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>-0.9641</td>  <td>0.6810</td>  <td>-1.4157</td> <td>0.1569</td> <td>-2.2988</td> <td>0.3707</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>S_No</th>                    <td>-0.0007</td>  <td>0.0001</td>  <td>-6.1017</td> <td>0.0000</td> <td>-0.0010</td> <td>-0.0005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1_A_Game_Of_Thrones</th> <td>-0.4379</td>  <td>0.1549</td>  <td>-2.8265</td> <td>0.0047</td> <td>-0.7415</td> <td>-0.1342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book2_A_Clash_Of_Kings</th>  <td>-0.3270</td>  <td>0.1356</td>  <td>-2.4111</td> <td>0.0159</td> <td>-0.5928</td> <td>-0.0612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th> <td>1.7022</td>   <td>0.1381</td>  <td>12.3258</td> <td>0.0000</td> <td>1.4315</td>  <td>1.9729</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_house</th>                 <td>0.3377</td>   <td>0.1602</td>  <td>2.1083</td>  <td>0.0350</td> <td>0.0238</td>  <td>0.6516</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_isAliveMother</th>         <td>2.1684</td>   <td>0.6768</td>  <td>3.2039</td>  <td>0.0014</td> <td>0.8419</td>  <td>3.4950</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_dead_relations</th>      <td>-0.9741</td>  <td>0.2192</td>  <td>-4.4443</td> <td>0.0000</td> <td>-1.4036</td> <td>-0.5445</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                            Results: Logit\n",
       "=======================================================================\n",
       "Model:                Logit              Pseudo R-squared:   0.134     \n",
       "Dependent Variable:   isAlive            AIC:                1734.4441 \n",
       "Date:                 2021-12-05 17:22   BIC:                1778.1876 \n",
       "No. Observations:     1751               Log-Likelihood:     -859.22   \n",
       "Df Model:             7                  LL-Null:            -992.53   \n",
       "Df Residuals:         1743               LLR p-value:        7.9817e-54\n",
       "Converged:            1.0000             Scale:              1.0000    \n",
       "No. Iterations:       6.0000                                           \n",
       "-----------------------------------------------------------------------\n",
       "                         Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------------\n",
       "Intercept               -0.9641   0.6810 -1.4157 0.1569 -2.2988  0.3707\n",
       "S_No                    -0.0007   0.0001 -6.1017 0.0000 -0.0010 -0.0005\n",
       "book1_A_Game_Of_Thrones -0.4379   0.1549 -2.8265 0.0047 -0.7415 -0.1342\n",
       "book2_A_Clash_Of_Kings  -0.3270   0.1356 -2.4111 0.0159 -0.5928 -0.0612\n",
       "book4_A_Feast_For_Crows  1.7022   0.1381 12.3258 0.0000  1.4315  1.9729\n",
       "m_house                  0.3377   0.1602  2.1083 0.0350  0.0238  0.6516\n",
       "m_isAliveMother          2.1684   0.6768  3.2039 0.0014  0.8419  3.4950\n",
       "has_dead_relations      -0.9741   0.2192 -4.4443 0.0000 -1.4036 -0.5445\n",
       "=======================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_sig_1 = smf.logit(formula   = \"\"\"isAlive ~ S_No + \n",
    " book1_A_Game_Of_Thrones + \n",
    " book2_A_Clash_Of_Kings + \n",
    " book4_A_Feast_For_Crows +\n",
    " m_house + \n",
    " m_isAliveMother +\n",
    " has_dead_relations\"\"\",\n",
    "                           data = got_train)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_sig_1.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49315b14",
   "metadata": {},
   "source": [
    "The logistic_sig_2 model was built with the same criteria as the first one. However, I tried to change the variables and include the m_age to observe how it would affect the Pseudo R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "3c1407d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.484654\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.145</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1713.2585</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 17:22</td>       <td>BIC:</td>         <td>1757.0020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-848.63</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>7</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1743</td>         <td>LLR p-value:</td>    <td>2.4217e-58</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>              <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>-1.6381</td>  <td>0.7008</td>  <td>-2.3376</td> <td>0.0194</td> <td>-3.0116</td> <td>-0.2646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>S_No</th>                    <td>-0.0007</td>  <td>0.0001</td>  <td>-6.1780</td> <td>0.0000</td> <td>-0.0010</td> <td>-0.0005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1_A_Game_Of_Thrones</th> <td>-0.4717</td>  <td>0.1553</td>  <td>-3.0375</td> <td>0.0024</td> <td>-0.7761</td> <td>-0.1673</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book2_A_Clash_Of_Kings</th>  <td>-0.2724</td>  <td>0.1374</td>  <td>-1.9827</td> <td>0.0474</td> <td>-0.5417</td> <td>-0.0031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th> <td>1.7668</td>   <td>0.1416</td>  <td>12.4760</td> <td>0.0000</td> <td>1.4892</td>  <td>2.0444</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_age</th>                   <td>0.7891</td>   <td>0.1498</td>  <td>5.2693</td>  <td>0.0000</td> <td>0.4956</td>  <td>1.0826</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_mother</th>                <td>2.2374</td>   <td>0.6790</td>  <td>3.2953</td>  <td>0.0010</td> <td>0.9066</td>  <td>3.5681</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numDeadRelations</th>        <td>-0.1114</td>  <td>0.0437</td>  <td>-2.5503</td> <td>0.0108</td> <td>-0.1970</td> <td>-0.0258</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                            Results: Logit\n",
       "=======================================================================\n",
       "Model:                Logit              Pseudo R-squared:   0.145     \n",
       "Dependent Variable:   isAlive            AIC:                1713.2585 \n",
       "Date:                 2021-12-05 17:22   BIC:                1757.0020 \n",
       "No. Observations:     1751               Log-Likelihood:     -848.63   \n",
       "Df Model:             7                  LL-Null:            -992.53   \n",
       "Df Residuals:         1743               LLR p-value:        2.4217e-58\n",
       "Converged:            1.0000             Scale:              1.0000    \n",
       "No. Iterations:       6.0000                                           \n",
       "-----------------------------------------------------------------------\n",
       "                         Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "-----------------------------------------------------------------------\n",
       "Intercept               -1.6381   0.7008 -2.3376 0.0194 -3.0116 -0.2646\n",
       "S_No                    -0.0007   0.0001 -6.1780 0.0000 -0.0010 -0.0005\n",
       "book1_A_Game_Of_Thrones -0.4717   0.1553 -3.0375 0.0024 -0.7761 -0.1673\n",
       "book2_A_Clash_Of_Kings  -0.2724   0.1374 -1.9827 0.0474 -0.5417 -0.0031\n",
       "book4_A_Feast_For_Crows  1.7668   0.1416 12.4760 0.0000  1.4892  2.0444\n",
       "m_age                    0.7891   0.1498  5.2693 0.0000  0.4956  1.0826\n",
       "m_mother                 2.2374   0.6790  3.2953 0.0010  0.9066  3.5681\n",
       "numDeadRelations        -0.1114   0.0437 -2.5503 0.0108 -0.1970 -0.0258\n",
       "=======================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_sig_2 = smf.logit(formula   = \"\"\"isAlive ~  S_No +  \n",
    " book1_A_Game_Of_Thrones + \n",
    " book2_A_Clash_Of_Kings + \n",
    " book4_A_Feast_For_Crows + \n",
    " m_age + \n",
    " m_mother +\n",
    " numDeadRelations\"\"\",\n",
    "                           data = got_train)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_sig_2.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f5309c",
   "metadata": {},
   "source": [
    "The logistic-full model was also built on the same criteria. Nevertheless, I left all variables that would make the model work, despite them being statistically not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "aaae5cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482665\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.148</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>      <td>isAlive</td>           <td>AIC:</td>         <td>1726.2921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-12-05 17:22</td>       <td>BIC:</td>         <td>1824.7150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>1751</td>        <td>Log-Likelihood:</td>    <td>-845.15</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>17</td>            <td>LL-Null:</td>        <td>-992.53</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>1733</td>         <td>LLR p-value:</td>    <td>1.3459e-52</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>               <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>-2.1119</td>  <td>0.9960</td>  <td>-2.1203</td> <td>0.0340</td> <td>-4.0641</td> <td>-0.1597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>S_No</th>                       <td>-0.0007</td>  <td>0.0001</td>  <td>-5.6260</td> <td>0.0000</td> <td>-0.0010</td> <td>-0.0005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book1_A_Game_Of_Thrones</th>    <td>-0.4877</td>  <td>0.1615</td>  <td>-3.0204</td> <td>0.0025</td> <td>-0.8042</td> <td>-0.1712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book2_A_Clash_Of_Kings</th>     <td>-0.2698</td>  <td>0.1397</td>  <td>-1.9308</td> <td>0.0535</td> <td>-0.5437</td> <td>0.0041</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book4_A_Feast_For_Crows</th>    <td>1.7403</td>   <td>0.1494</td>  <td>11.6514</td> <td>0.0000</td> <td>1.4476</td>  <td>2.0331</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>book5_A_Dance_with_Dragons</th> <td>0.1691</td>   <td>0.1507</td>  <td>1.1223</td>  <td>0.2617</td> <td>-0.1262</td> <td>0.4645</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isNoble</th>                    <td>-0.0713</td>  <td>0.4616</td>  <td>-0.1544</td> <td>0.8773</td> <td>-0.9759</td> <td>0.8334</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numDeadRelations</th>           <td>-0.0518</td>  <td>0.0642</td>  <td>-0.8060</td> <td>0.4202</td> <td>-0.1776</td> <td>0.0741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>popularity</th>                 <td>0.0445</td>   <td>0.5241</td>  <td>0.0849</td>  <td>0.9324</td> <td>-0.9827</td> <td>1.0717</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_title</th>                    <td>-0.0234</td>  <td>0.4595</td>  <td>-0.0510</td> <td>0.9593</td> <td>-0.9241</td> <td>0.8772</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_culture</th>                  <td>0.0173</td>   <td>0.1335</td>  <td>0.1296</td>  <td>0.8969</td> <td>-0.2443</td> <td>0.2789</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_house</th>                    <td>0.2749</td>   <td>0.1667</td>  <td>1.6490</td>  <td>0.0991</td> <td>-0.0518</td> <td>0.6016</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_isAliveMother</th>            <td>1.8473</td>   <td>1.2357</td>  <td>1.4949</td>  <td>0.1349</td> <td>-0.5746</td> <td>4.2692</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_isAliveFather</th>            <td>-0.0694</td>  <td>1.0531</td>  <td>-0.0659</td> <td>0.9475</td> <td>-2.1334</td> <td>1.9946</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_isAliveHeir</th>              <td>0.7863</td>   <td>0.9002</td>  <td>0.8734</td>  <td>0.3824</td> <td>-0.9782</td> <td>2.5507</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_isAliveSpouse</th>            <td>0.1159</td>   <td>0.1859</td>  <td>0.6235</td>  <td>0.5329</td> <td>-0.2485</td> <td>0.4803</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>m_age</th>                      <td>0.7461</td>   <td>0.1575</td>  <td>4.7373</td>  <td>0.0000</td> <td>0.4374</td>  <td>1.0547</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_dead_relations</th>         <td>-0.3803</td>  <td>0.3440</td>  <td>-1.1055</td> <td>0.2689</td> <td>-1.0545</td> <td>0.2939</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                              Results: Logit\n",
       "==========================================================================\n",
       "Model:                 Logit               Pseudo R-squared:    0.148     \n",
       "Dependent Variable:    isAlive             AIC:                 1726.2921 \n",
       "Date:                  2021-12-05 17:22    BIC:                 1824.7150 \n",
       "No. Observations:      1751                Log-Likelihood:      -845.15   \n",
       "Df Model:              17                  LL-Null:             -992.53   \n",
       "Df Residuals:          1733                LLR p-value:         1.3459e-52\n",
       "Converged:             1.0000              Scale:               1.0000    \n",
       "No. Iterations:        6.0000                                             \n",
       "--------------------------------------------------------------------------\n",
       "                            Coef.  Std.Err.    z    P>|z|   [0.025  0.975]\n",
       "--------------------------------------------------------------------------\n",
       "Intercept                  -2.1119   0.9960 -2.1203 0.0340 -4.0641 -0.1597\n",
       "S_No                       -0.0007   0.0001 -5.6260 0.0000 -0.0010 -0.0005\n",
       "book1_A_Game_Of_Thrones    -0.4877   0.1615 -3.0204 0.0025 -0.8042 -0.1712\n",
       "book2_A_Clash_Of_Kings     -0.2698   0.1397 -1.9308 0.0535 -0.5437  0.0041\n",
       "book4_A_Feast_For_Crows     1.7403   0.1494 11.6514 0.0000  1.4476  2.0331\n",
       "book5_A_Dance_with_Dragons  0.1691   0.1507  1.1223 0.2617 -0.1262  0.4645\n",
       "isNoble                    -0.0713   0.4616 -0.1544 0.8773 -0.9759  0.8334\n",
       "numDeadRelations           -0.0518   0.0642 -0.8060 0.4202 -0.1776  0.0741\n",
       "popularity                  0.0445   0.5241  0.0849 0.9324 -0.9827  1.0717\n",
       "m_title                    -0.0234   0.4595 -0.0510 0.9593 -0.9241  0.8772\n",
       "m_culture                   0.0173   0.1335  0.1296 0.8969 -0.2443  0.2789\n",
       "m_house                     0.2749   0.1667  1.6490 0.0991 -0.0518  0.6016\n",
       "m_isAliveMother             1.8473   1.2357  1.4949 0.1349 -0.5746  4.2692\n",
       "m_isAliveFather            -0.0694   1.0531 -0.0659 0.9475 -2.1334  1.9946\n",
       "m_isAliveHeir               0.7863   0.9002  0.8734 0.3824 -0.9782  2.5507\n",
       "m_isAliveSpouse             0.1159   0.1859  0.6235 0.5329 -0.2485  0.4803\n",
       "m_age                       0.7461   0.1575  4.7373 0.0000  0.4374  1.0547\n",
       "has_dead_relations         -0.3803   0.3440 -1.1055 0.2689 -1.0545  0.2939\n",
       "==========================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_full = smf.logit(formula   = \"\"\"isAlive ~  S_No +  \n",
    " book1_A_Game_Of_Thrones + \n",
    " book2_A_Clash_Of_Kings + \n",
    " book4_A_Feast_For_Crows + \n",
    " book5_A_Dance_with_Dragons + \n",
    " isNoble +  \n",
    " numDeadRelations + \n",
    " popularity + \n",
    " m_title + \n",
    " m_culture + \n",
    " m_house + \n",
    " m_isAliveMother + \n",
    " m_isAliveFather + \n",
    " m_isAliveHeir + \n",
    " m_isAliveSpouse + \n",
    " m_age + \n",
    " has_dead_relations \"\"\",\n",
    "                           data = got_train)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9984aacf",
   "metadata": {},
   "source": [
    "# Logistic Regression in Sci-Kit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bdfbde",
   "metadata": {},
   "source": [
    "The following code is used to give a name to the different models and ease the process by imputing the name in the code instead of all the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "071d7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary to store candidate models\n",
    "\n",
    "candidate_dict = {\n",
    "\n",
    " # full model\n",
    " 'logit_full'   : ['S_No', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', \n",
    "                   'book4_A_Feast_For_Crows', 'book5_A_Dance_with_Dragons', \n",
    "                   'isNoble', 'numDeadRelations', 'popularity', 'm_title', \n",
    "                   'm_culture', 'm_house', 'm_isAliveMother', 'm_isAliveFather', \n",
    "                   'm_isAliveHeir', 'm_isAliveSpouse', 'm_age', 'has_dead_relations'],\n",
    " \n",
    "\n",
    " # significant variables only (set 1)\n",
    " 'logit_sig_1'  : ['S_No', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings',\n",
    "                   'm_house', 'book4_A_Feast_For_Crows', 'm_isAliveMother',\n",
    "                   'has_dead_relations'],\n",
    "    \n",
    "    \n",
    " # significant variables only (set 2)\n",
    " 'logit_sig_2'  : ['S_No', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', \n",
    "                   'book4_A_Feast_For_Crows', 'm_mother', 'm_age', \n",
    "                   'numDeadRelations']\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f325025d",
   "metadata": {},
   "source": [
    "## Dynamically printing each explanatory variable set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "89ac7138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/--------------------------\\\n",
      "|Explanatory Variable Sets |\n",
      "\\--------------------------/\n",
      "\n",
      "Full Model:\n",
      "-----------\n",
      "['S_No', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'book4_A_Feast_For_Crows', 'book5_A_Dance_with_Dragons', 'isNoble', 'numDeadRelations', 'popularity', 'm_title', 'm_culture', 'm_house', 'm_isAliveMother', 'm_isAliveFather', 'm_isAliveHeir', 'm_isAliveSpouse', 'm_age', 'has_dead_relations']\n",
      "\n",
      "\n",
      "First Significant p-value Model:\n",
      "--------------------------------\n",
      "['S_No', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'm_house', 'book4_A_Feast_For_Crows', 'm_isAliveMother', 'has_dead_relations']\n",
      "\n",
      "\n",
      "Second Significant p-value Model:\n",
      "---------------------------------\n",
      "['S_No', 'book1_A_Game_Of_Thrones', 'book2_A_Clash_Of_Kings', 'book4_A_Feast_For_Crows', 'm_mother', 'm_age', 'numDeadRelations']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing candidate variable sets\n",
    "print(f\"\"\"\n",
    "/--------------------------\\\\\n",
    "|Explanatory Variable Sets |\n",
    "\\\\--------------------------/\n",
    "\n",
    "Full Model:\n",
    "-----------\n",
    "{candidate_dict['logit_full']}\n",
    "\n",
    "\n",
    "First Significant p-value Model:\n",
    "--------------------------------\n",
    "{candidate_dict['logit_sig_1']}\n",
    "\n",
    "\n",
    "Second Significant p-value Model:\n",
    "---------------------------------\n",
    "{candidate_dict['logit_sig_2']}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4778b",
   "metadata": {},
   "source": [
    "## Building a logistic regression model in scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "150e1bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.767\n",
      "Testing  ACCURACY: 0.8513\n",
      "AUC Score: 0.7428\n"
     ]
    }
   ],
   "source": [
    "# train/test split with the full model\n",
    "got_df_data   =  got_df.loc[ : , candidate_dict['logit_sig_1']]\n",
    "got_df_target =  got_df.loc[ : , 'isAlive']\n",
    "\n",
    "\n",
    "# This is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_df_data,\n",
    "            got_df_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = got_df_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4) # accuracy\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "2bf25ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 26\n",
      "False Positives: 24\n",
      "False Negatives: 5\n",
      "True Positives : 140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270fd859",
   "metadata": {},
   "source": [
    "# Classification Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a39fd1",
   "metadata": {},
   "source": [
    "## Full Classification Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "f9b650e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Tree Training ACCURACY: 1.0\n",
      "Full Tree Testing ACCURACY : 0.6769\n",
      "Full Tree AUC Score: 0.619\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train,\n",
    "                                                     y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test,\n",
    "                                                     y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "e3fb95d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 25\n",
      "False Positives: 25\n",
      "False Negatives: 38\n",
      "True Positives : 107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {full_tree_tn}\n",
    "False Positives: {full_tree_fp}\n",
    "False Negatives: {full_tree_fn}\n",
    "True Positives : {full_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dded00e4",
   "metadata": {},
   "source": [
    "## Pruned Classification Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "e574428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7801\n",
      "Testing  ACCURACY: 0.8205\n",
      "AUC Score        : 0.7417\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "tree_pruned = DecisionTreeClassifier(max_depth = 4,\n",
    "                    min_samples_leaf = 25,\n",
    "                    random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "tree_pruned_fit = tree_pruned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "tree_pred = tree_pruned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', tree_pruned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_pruned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_pruned_train_score = tree_pruned_fit.score(x_train, y_train).round(4) # accuracy\n",
    "tree_pruned_test_score  = tree_pruned_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "tree_pruned_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "12aa3d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 29\n",
      "False Positives: 21\n",
      "False Negatives: 14\n",
      "True Positives : 131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "tree_pruned_tn, \\\n",
    "tree_pruned_fp, \\\n",
    "tree_pruned_fn, \\\n",
    "tree_pruned_tp = confusion_matrix(y_true = y_test, y_pred = tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tree_pruned_tn}\n",
    "False Positives: {tree_pruned_fp}\n",
    "False Negatives: {tree_pruned_fn}\n",
    "True Positives : {tree_pruned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c4563d",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ffe2f6",
   "metadata": {},
   "source": [
    "## Importing Remaining Necessary Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "7741d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new tools\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "\n",
    "#machine learning\n",
    "from sklearn.model_selection import RandomizedSearchCV # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer                # customizable scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257acdfc",
   "metadata": {},
   "source": [
    "## Default Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "080aad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = 4,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "39a381d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7744\n",
      "Testing  ACCURACY: 0.841\n",
      "AUC Score        : 0.69\n"
     ]
    }
   ],
   "source": [
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "rf_train_score = rf_default_fit.score(x_train, y_train).round(4) # accuracy\n",
    "rf_test_score  = rf_default_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "rf_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "f2ff0379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 19\n",
      "False Positives: 31\n",
      "False Negatives: 0\n",
      "True Positives : 145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "rf_tn, \\\n",
    "rf_fp, \\\n",
    "rf_fn, \\\n",
    "rf_tp = confusion_matrix(y_true = y_test, y_pred = rf_default_fit_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {rf_tn}\n",
    "False Positives: {rf_fp}\n",
    "False Negatives: {rf_fn}\n",
    "True Positives : {rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c187aec3",
   "metadata": {},
   "source": [
    "## Tuning Model's Hyper-parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859ea3d2",
   "metadata": {},
   "source": [
    "In the following cell, the n_iter has been fixed to 96 after Python informed me it could no go over 96 iterations considering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "63d5a2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters  : {'warm_start': True, 'n_estimators': 100, 'min_samples_leaf': 21, 'criterion': 'gini', 'bootstrap': True}\n",
      "Tuned Training AUC: 0.5051\n"
     ]
    }
   ],
   "source": [
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "estimator_range  = np.arange(100, 1100, 250)\n",
    "leaf_range       = np.arange(1, 31, 10)\n",
    "criterion_range  = ['gini', 'entropy']\n",
    "bootstrap_range  = [True, False]\n",
    "warm_start_range = [True, False]\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'n_estimators'     : estimator_range,\n",
    "              'min_samples_leaf' : leaf_range,\n",
    "              'criterion'        : criterion_range,\n",
    "              'bootstrap'        : bootstrap_range,\n",
    "              'warm_start'       : warm_start_range}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "                               param_distributions = param_grid,\n",
    "                               cv         = 3,\n",
    "                               n_iter     = 96,\n",
    "                               scoring    = make_scorer(roc_auc_score,\n",
    "                                            needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "forest_cv.fit(got_df_data, got_df_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "a459268a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_leaf=21, random_state=219, warm_start=True)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best estimators based on RandomizedSearchCV\n",
    "forest_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61765cae",
   "metadata": {},
   "source": [
    "## Tuned Forest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "bc3a7bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Tuned Training ACCURACY: 0.7773\n",
      "Forest Tuned Testing  ACCURACY: 0.8615\n",
      "Forest Tuned AUC Score        : 0.7366\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING with best_estimator\n",
    "forest_tuned = RandomForestClassifier(criterion='gini', min_samples_leaf=21,\n",
    "                       n_estimators=600, random_state=219, warm_start=True,\n",
    "                                     bootstrap = True)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "forest_tuned_fit = forest_tuned.fit(got_df_data, got_df_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "forest_tuned_pred = forest_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned.score(x_train, y_train).round(4))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned.score(x_test, y_test).round(4))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                       y_score = forest_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "forest_tuned_test_score  = forest_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "forest_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = forest_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "7b1de561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 24\n",
      "False Positives: 26\n",
      "False Negatives: 1\n",
      "True Positives : 144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_rf_tn, \\\n",
    "tuned_rf_fp, \\\n",
    "tuned_rf_fn, \\\n",
    "tuned_rf_tp = confusion_matrix(y_true = y_test, y_pred = forest_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_rf_tn}\n",
    "False Positives: {tuned_rf_fp}\n",
    "False Negatives: {tuned_rf_fn}\n",
    "True Positives : {tuned_rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371d3b11",
   "metadata": {},
   "source": [
    "# Gradient Boosted Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a12ecf",
   "metadata": {},
   "source": [
    "## Full Gradient Boosted Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "54d442db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8172\n",
      "Testing ACCURACY : 0.8256\n",
      "AUC Score        : 0.7255\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_default = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.1,\n",
    "                                              n_estimators  = 100,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 3,\n",
    "                                              warm_start    = False,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "full_gbm_default_fit = full_gbm_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "full_gbm_default_pred = full_gbm_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_default_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_default_pred).round(4))\n",
    "\n",
    "#Saving the results for future use\n",
    "full_gbm_training = full_gbm_default_fit.score(x_train, y_train).round(4)\n",
    "full_gbm_test     = full_gbm_default_fit.score(x_test, y_test).round(4)\n",
    "full_gbm_auc      =  roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_default_pred).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "277cd1f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 26\n",
      "False Positives: 24\n",
      "False Negatives: 10\n",
      "True Positives : 135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_default_tn, \\\n",
    "gbm_default_fp, \\\n",
    "gbm_default_fn, \\\n",
    "gbm_default_tp = confusion_matrix(y_true = y_test, y_pred = full_gbm_default_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_default_tn}\n",
    "False Positives: {gbm_default_fp}\n",
    "False Negatives: {gbm_default_fn}\n",
    "True Positives : {gbm_default_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0686f8",
   "metadata": {},
   "source": [
    "## Tuning Model's Hyper-parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c96a992",
   "metadata": {},
   "source": [
    "Running the following code ended up in not complying to the time restrictions. However, to in order to have a better understanding of the values in the tuned GBM model, I left the whole code but put every line as a comment so it would not affect the execution time. The parameters in the Tuned model have been filled after the two following cells ran the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "2ae688d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "#learn_range        = np.arange(0.1, 2.2, 0.5)\n",
    "#estimator_range    = np.arange(100, 501, 25)\n",
    "#depth_range        = np.arange(2, 11, 2)\n",
    "#warm_start_range   = [True, False]\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'learning_rate' : learn_range,\n",
    "#              'max_depth'     : depth_range,\n",
    "#              'n_estimators'  : estimator_range,\n",
    "#              'warm_start'    : warm_start_range}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#full_gbm_grid = GradientBoostingClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "#full_gbm_cv = RandomizedSearchCV(estimator     = full_gbm_grid,\n",
    "#                           param_distributions = param_grid,\n",
    "#                          cv                  = 3,\n",
    "#                           n_iter              = 500,\n",
    "#                           random_state        = 219,\n",
    "#                           scoring             = make_scorer(roc_auc_score,\n",
    "#                                                 needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#full_gbm_cv.fit(got_df_data, got_df_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "22592542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the best estimator for the model\n",
    "#full_gbm_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b07d193",
   "metadata": {},
   "source": [
    "## Tuned Gradient Boosted Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "7ff8c484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7984\n",
      "Testing  ACCURACY: 0.8615\n",
      "AUC Score        : 0.7824\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING with best_estimator\n",
    "gbm_tuned = GradientBoostingClassifier(learning_rate = 0.1,\n",
    "                                       max_depth     = 2,\n",
    "                                       n_estimators  = 125,\n",
    "                                       warm_start    = False,\n",
    "                                       random_state  = 219)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "gbm_tuned_fit = gbm_tuned.fit(got_df_data, got_df_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))\n",
    "\n",
    "#Saving the results for future use\n",
    "gbm_tuned_training = gbm_tuned_fit.score(x_train, y_train).round(4)\n",
    "gbm_tuned_test     = gbm_tuned_fit.score(x_test, y_test).round(4)\n",
    "gbm_tuned_auc      = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "0dd73819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 31\n",
      "False Positives: 19\n",
      "False Negatives: 8\n",
      "True Positives : 137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_tuned_tn, \\\n",
    "gbm_tuned_fp, \\\n",
    "gbm_tuned_fn, \\\n",
    "gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_tuned_tn}\n",
    "False Positives: {gbm_tuned_fp}\n",
    "False Negatives: {gbm_tuned_fn}\n",
    "True Positives : {gbm_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349404cd",
   "metadata": {},
   "source": [
    "# Classification Modeling with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "e029cbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7796\n",
      "Testing  ACCURACY: 0.8205\n",
      "AUC Score        : 0.6828\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the data\n",
    "scaler.fit(got_df_data)\n",
    "\n",
    "\n",
    "# TRANSFORMING the data\n",
    "x_scaled     = scaler.transform(got_df_data)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "x_scaled_df  = pd.DataFrame(x_scaled) \n",
    "\n",
    "\n",
    "# train-test split with the scaled data\n",
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "            x_scaled_df,\n",
    "            got_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.10,\n",
    "            stratify     = got_df_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(x_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(x_test_scaled)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(x_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(x_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(x_train_scaled, y_train_scaled).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test_scaled, y_test_scaled).round(4)\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "37fd8c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 20\n",
      "False Positives: 30\n",
      "False Negatives: 5\n",
      "True Positives : 140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "knn_tree_tn, \\\n",
    "knn_tree_fp, \\\n",
    "knn_tree_fn, \\\n",
    "knn_tree_tp = confusion_matrix(y_true = y_test, y_pred = knn_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {knn_tree_tn}\n",
    "False Positives: {knn_tree_fp}\n",
    "False Negatives: {knn_tree_fn}\n",
    "True Positives : {knn_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d285c7",
   "metadata": {},
   "source": [
    "# Model Comparison and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "4e27d1b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model        Training Acc      Testing Acc      AUC Score      TN, FP, FN, TP\n",
      "-----        ------------      -----------      ---------      --------------\n",
      "Logistic       0.767              0.8513         0.7428       (26, 24, 5, 140)\n",
      "Full Tree      1.0                0.6769         0.619        (25, 25, 38, 107)\n",
      "Pruned Tree    0.7801             0.8205         0.7417       (29, 21, 14, 131)  \n",
      "Random Forest  0.7744             0.841          0.69         (19, 31, 0, 145)\n",
      "Forest Tuned   0.7773             0.8615         0.7366       (24, 26, 1, 144)\n",
      "Full gbm       0.8172             0.8256         0.7255       (26, 24, 10, 135)\n",
      "Tuned gbm(*)   0.7984             0.8615         0.7824       (31, 19, 8, 137)\n",
      "KNN Tree       0.7796             0.8205         0.6828       (20, 30, 5, 140)\n",
      "\n",
      "\n",
      "(*Final model)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing models\n",
    "print(f\"\"\"\n",
    "Model        Training Acc      Testing Acc      AUC Score      TN, FP, FN, TP\n",
    "-----        ------------      -----------      ---------      --------------\n",
    "Logistic       {logreg_train_score}              {logreg_test_score}         {logreg_auc_score}       {logreg_tn, logreg_fp, logreg_fn, logreg_tp}\n",
    "Full Tree      {full_tree_train_score}                {full_tree_test_score}         {full_tree_auc_score}        {full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp}\n",
    "Pruned Tree    {tree_pruned_train_score}             {tree_pruned_test_score}         {tree_pruned_auc_score}       {tree_pruned_tn, tree_pruned_fp, tree_pruned_fn, tree_pruned_tp}  \n",
    "Random Forest  {rf_train_score}             {rf_test_score}          {rf_auc_score}         {rf_tn, rf_fp, rf_fn, rf_tp}\n",
    "Forest Tuned   {forest_tuned_train_score}             {forest_tuned_test_score}         {forest_tuned_auc}       {tuned_rf_tn, tuned_rf_fp, tuned_rf_fn, tuned_rf_tp}\n",
    "Full gbm       {full_gbm_training}             {full_gbm_test}         {full_gbm_auc}       {gbm_default_tn, gbm_default_fp, gbm_default_fn, gbm_default_tp}\n",
    "Tuned gbm(*)   {gbm_tuned_training}             {gbm_tuned_test}         {gbm_tuned_auc}       {gbm_tuned_tn, gbm_tuned_fp, gbm_tuned_fn, gbm_tuned_tp}\n",
    "KNN Tree       {knn_train_score}             {knn_test_score}         {knn_auc_score}       {knn_tree_tn, knn_tree_fp, knn_tree_fn, knn_tree_tp}\n",
    "\n",
    "\n",
    "(*Final model)\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
